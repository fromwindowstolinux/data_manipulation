# Scraping, storing and processing

## Part 1: Web Scraping and Database Storage

- Url to scrap: https://zuscoffee.com/category/store/melaka

- Scrape the names and addresses of outlets from a given webpage that has multiple pages
of content. Ensure your script can handle pagination to navigate through all available pages.

- Store the scraped data into a database, designing the schema in a way that you find suitable
for this task.

## Part 2: Geocoding

- For each outlet, retrieve its geographical coordinates based on the stored address. Use
Open Street Maps (it’s FREE!)

## Part 3: API Development

- Develop a backend API to serve the outlet data, including their geographical coordinates.

## Part 4: Frontend Development and Visualization

- Create a web application that interacts with your API to visualize the outlets on a map.

- Implement functionality to display a 5KM radius catchment around each outlet on the map.

- Highlight or mark the outlets that intersect with any other outlet’s 5KM radius catchment.

## Part 5: Documentation and Instructions

- Provide documentation with instructions on how to set up and run your application, and any
other necessary information required to understand and use your solution. (hint: figure out
how to use AI to do this)